{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAT.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"7HPxbz9IZ1xO","colab_type":"code","colab":{}},"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kIH9phOegalY","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install tensorflow-gpu==2.0.0-alpha0\n","!pip install -q keras"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5PIfldx7gczn","colab_type":"code","colab":{}},"cell_type":"code","source":["import os,sys,inspect\n","import os\n","import joblib\n","import numpy as np\n","import h5py\n","import scipy.sparse.linalg as la\n","import scipy.sparse as sp\n","import scipy\n","import time\n","import pickle\n","\n","import tensorflow as tf\n","\n","from tensorflow.keras import activations\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Layer, Input, Dense, Activation, Dropout, LeakyReLU, Softmax, ELU\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras import Model\n","\n","import matplotlib.pyplot as plt\n","from matplotlib.backends.backend_pdf import PdfPages\n","%matplotlib inline\n","\n","import scipy.io as sio\n","import process_data"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GA_7oCF3iSuG","colab_type":"code","colab":{}},"cell_type":"code","source":["# # Load dataset from local\n","\n","# from google.colab import files\n","# uploaded = files.upload()\n","\n","# for fn in uploaded.keys():\n","#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","#       name=fn, length=len(uploaded[fn])))\n"," \n","!unzip -o data.zip"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WQ16sP9CKMDg","colab_type":"code","outputId":"d5667e17-14d2-4173-f2ad-8bb25d12d15b","executionInfo":{"status":"ok","timestamp":1555601037305,"user_tz":-120,"elapsed":751,"user":{"displayName":"Alessia Ruggeri","photoUrl":"","userId":"01098494933204128714"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["# Dataset loading\n","\n","A, X, Y, train_idx, val_idx, test_idx = process_data.load_data(\"cora\")\n","X = process_data.preprocess_features(X)"],"execution_count":110,"outputs":[{"output_type":"stream","text":["(2708, 2708)\n","(2708, 1433)\n"],"name":"stdout"}]},{"metadata":{"id":"Ktxot85P9n5y","colab_type":"code","colab":{}},"cell_type":"code","source":["def mask_data(X, idx):\n","  new = np.zeros(X.shape)\n","  mask = np.zeros(X.shape[0]).astype(np.bool)\n","  mask[idx] = 1\n","  new[mask, :] = X[mask, :]\n","  \n","  return new"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W0Sks2femqFP","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create attention\n","\n","class Attention(Layer):\n","  \n","  def __init__(self, F_1, kernel_regularizer, **kwargs):\n","    self.F_1 = F_1\n","    self.kernel_regularizer = kernel_regularizer\n","    super(Attention, self).__init__(**kwargs)\n","\n","  def build(self, input_shape):\n","    F = input_shape[0][-1]\n","    self.W = self.add_weight(name='W', \n","                             shape=(self.F_1, F),\n","                             initializer='glorot_uniform',\n","                             regularizer=self.kernel_regularizer,\n","                             trainable=True)\n","\n","    self.a = self.add_weight(name='a', \n","                             shape=(2, self.F_1, 1),\n","                             initializer='glorot_uniform',\n","                             regularizer=self.kernel_regularizer,\n","                             trainable=True)\n","\n","    super(Attention, self).build(input_shape)  # Be sure to call this at the end\n","   \n","  def call(self, inputs):\n","    X = inputs[0]\n","    A = inputs[1]\n","\n","    x_features = X @ tf.transpose(self.W)\n","#     x_features = (N, F_1)\n","    att_self = x_features @ self.a[0]\n","    att_neighbours = x_features @ self.a[1]\n","#     both att = (N, 1)\n","    att = att_self + tf.transpose(att_neighbours)\n","#     att = (N, N)\n","    att = LeakyReLU(alpha=0.2)(att)\n","\n","    mask = -10e9 * (1.0 - A)\n","    att_masked = att + mask\n","#     att_masked = att * A\n","    dense = Softmax(axis=0)(att_masked)\n","    \n","#     dense = (N, N)\n","    dense = dense @ x_features\n","#     dense = (N, F_1)\n","\n","    return dense\n","\n","  def compute_output_shape(self, input_shape):\n","    return (input_shape[0][0], self.output_dim)\n","    \n","\n","\n","# Create Gaussian (kernel) layer\n","\n","class GAT(Layer):\n","  \n","  def __init__(self, F_1, K, kernel_regularizer, last=False, **kwargs):\n","    self.F_1 = F_1\n","    self.K = K\n","    self.kernel_regularizer = kernel_regularizer\n","    self.last = last\n","    \n","    self.attentions = []\n","    for k in range(self.K):\n","      attention = Attention(self.F_1, self.kernel_regularizer)\n","      self.attentions.append(attention)\n","      \n","    super(GAT, self).__init__(**kwargs)\n","  \n","  def build(self, input_shape):\n","\n","    super(GAT, self).build(input_shape)  # Be sure to call this at the end\n","   \n","  def call(self, inputs):\n","    X = inputs[0]\n","    A = inputs[1]\n","\n","    attentions = []\n","    for k in range(self.K):\n","      attention = self.attentions[k]([X, A])\n","      attentions.append(attention)\n","\n","    if self.last:\n","#       h = (N, F_1)\n","      h = tf.reduce_mean(tf.stack(attentions), axis=0)\n","      h = Softmax()(h)\n","    else:\n","#       h = (N, F_1*k)\n","      h = tf.concat(attentions, axis=1)\n","      h = ELU()(h)\n","    return h\n","\n","  def compute_output_shape(self, input_shape):\n","    return (input_shape[0][0], self.output_dim)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZvV6rS1omqVA","colab_type":"code","colab":{}},"cell_type":"code","source":["epochs=300\n","batch_size = X.shape[0]\n","n_classes = 7\n","F_1 = 8\n","K = 8\n","dropout = 0.5\n","learning_rate = 5e-3\n","reg = l2(5e-4)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FVrgsA4NkPEd","colab_type":"code","colab":{}},"cell_type":"code","source":["X_in = Input(shape=(X.shape[-1],))\n","A_in = Input(shape=(batch_size,))\n","\n","dropout1 = Dropout(dropout)(X_in)\n","layer1 = GAT(F_1=F_1,\n","             K=K,\n","             kernel_regularizer=reg,\n","             last=False,\n","             trainable=True,\n","             input_shape=(X.shape[-1],))([dropout1, A_in])\n","dropout2 = Dropout(dropout)(layer1)\n","layer2 = GAT(F_1=n_classes,\n","             K=1,\n","             kernel_regularizer=reg,\n","             last=True,\n","             trainable=True)([dropout2, A_in])\n","\n","model = Model(inputs=[X_in, A_in], outputs=layer2)\n","\n","model.compile(optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yefbAnMPBOk-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":10251},"outputId":"b0530cf3-2199-4d66-fbac-d9764a31fbaa","executionInfo":{"status":"ok","timestamp":1555601171387,"user_tz":-120,"elapsed":91346,"user":{"displayName":"Alessia Ruggeri","photoUrl":"","userId":"01098494933204128714"}}},"cell_type":"code","source":["validation_data = ([mask_data(X, val_idx), A], mask_data(Y, val_idx))\n","model.fit([mask_data(X, train_idx), A], mask_data(Y, train_idx), validation_data=validation_data, epochs=epochs, batch_size=batch_size, shuffle=False)"],"execution_count":115,"outputs":[{"output_type":"stream","text":["Train on 2708 samples, validate on 2708 samples\n","Epoch 1/300\n","2708/2708 [==============================] - 2s 702us/sample - loss: 0.1791 - accuracy: 0.5266 - val_loss: 0.4247 - val_accuracy: 0.3143\n","Epoch 2/300\n","2708/2708 [==============================] - 0s 114us/sample - loss: 0.1660 - accuracy: 0.5218 - val_loss: 0.4130 - val_accuracy: 0.3781\n","Epoch 3/300\n","2708/2708 [==============================] - 0s 112us/sample - loss: 0.1543 - accuracy: 0.5565 - val_loss: 0.4031 - val_accuracy: 0.3431\n","Epoch 4/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1443 - accuracy: 0.5975 - val_loss: 0.3949 - val_accuracy: 0.3892\n","Epoch 5/300\n","2708/2708 [==============================] - 0s 105us/sample - loss: 0.1361 - accuracy: 0.5447 - val_loss: 0.3883 - val_accuracy: 0.4202\n","Epoch 6/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1294 - accuracy: 0.5971 - val_loss: 0.3830 - val_accuracy: 0.4442\n","Epoch 7/300\n","2708/2708 [==============================] - 0s 106us/sample - loss: 0.1242 - accuracy: 0.5849 - val_loss: 0.3790 - val_accuracy: 0.4863\n","Epoch 8/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1201 - accuracy: 0.6023 - val_loss: 0.3759 - val_accuracy: 0.4911\n","Epoch 9/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1170 - accuracy: 0.6078 - val_loss: 0.3738 - val_accuracy: 0.4812\n","Epoch 10/300\n","2708/2708 [==============================] - 0s 105us/sample - loss: 0.1148 - accuracy: 0.6470 - val_loss: 0.3723 - val_accuracy: 0.5617\n","Epoch 11/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1134 - accuracy: 0.6034 - val_loss: 0.3714 - val_accuracy: 0.5731\n","Epoch 12/300\n","2708/2708 [==============================] - 0s 105us/sample - loss: 0.1125 - accuracy: 0.6780 - val_loss: 0.3708 - val_accuracy: 0.5535\n","Epoch 13/300\n","2708/2708 [==============================] - 0s 106us/sample - loss: 0.1119 - accuracy: 0.6385 - val_loss: 0.3705 - val_accuracy: 0.5905\n","Epoch 14/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1116 - accuracy: 0.6436 - val_loss: 0.3704 - val_accuracy: 0.5764\n","Epoch 15/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1116 - accuracy: 0.6340 - val_loss: 0.3704 - val_accuracy: 0.6152\n","Epoch 16/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1115 - accuracy: 0.6167 - val_loss: 0.3704 - val_accuracy: 0.6222\n","Epoch 17/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1115 - accuracy: 0.6222 - val_loss: 0.3704 - val_accuracy: 0.6137\n","Epoch 18/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1115 - accuracy: 0.6610 - val_loss: 0.3703 - val_accuracy: 0.6558\n","Epoch 19/300\n","2708/2708 [==============================] - 0s 105us/sample - loss: 0.1114 - accuracy: 0.6544 - val_loss: 0.3701 - val_accuracy: 0.6374\n","Epoch 20/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1112 - accuracy: 0.6706 - val_loss: 0.3698 - val_accuracy: 0.6473\n","Epoch 21/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1109 - accuracy: 0.7175 - val_loss: 0.3694 - val_accuracy: 0.6721\n","Epoch 22/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1105 - accuracy: 0.6481 - val_loss: 0.3690 - val_accuracy: 0.6547\n","Epoch 23/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1101 - accuracy: 0.7293 - val_loss: 0.3685 - val_accuracy: 0.6651\n","Epoch 24/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1096 - accuracy: 0.6300 - val_loss: 0.3680 - val_accuracy: 0.6544\n","Epoch 25/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1091 - accuracy: 0.7363 - val_loss: 0.3675 - val_accuracy: 0.6835\n","Epoch 26/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1086 - accuracy: 0.6898 - val_loss: 0.3670 - val_accuracy: 0.6872\n","Epoch 27/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1081 - accuracy: 0.7042 - val_loss: 0.3664 - val_accuracy: 0.6629\n","Epoch 28/300\n","2708/2708 [==============================] - 0s 105us/sample - loss: 0.1076 - accuracy: 0.7397 - val_loss: 0.3660 - val_accuracy: 0.6658\n","Epoch 29/300\n","2708/2708 [==============================] - 0s 105us/sample - loss: 0.1072 - accuracy: 0.7315 - val_loss: 0.3655 - val_accuracy: 0.6688\n","Epoch 30/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1067 - accuracy: 0.7038 - val_loss: 0.3651 - val_accuracy: 0.7374\n","Epoch 31/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1063 - accuracy: 0.7710 - val_loss: 0.3648 - val_accuracy: 0.7507\n","Epoch 32/300\n","2708/2708 [==============================] - 0s 105us/sample - loss: 0.1060 - accuracy: 0.7145 - val_loss: 0.3644 - val_accuracy: 0.7419\n","Epoch 33/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1057 - accuracy: 0.7182 - val_loss: 0.3642 - val_accuracy: 0.7437\n","Epoch 34/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1054 - accuracy: 0.7205 - val_loss: 0.3639 - val_accuracy: 0.7614\n","Epoch 35/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1052 - accuracy: 0.7489 - val_loss: 0.3637 - val_accuracy: 0.7792\n","Epoch 36/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1050 - accuracy: 0.7459 - val_loss: 0.3635 - val_accuracy: 0.7821\n","Epoch 37/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1048 - accuracy: 0.7659 - val_loss: 0.3634 - val_accuracy: 0.7725\n","Epoch 38/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1046 - accuracy: 0.7563 - val_loss: 0.3632 - val_accuracy: 0.7836\n","Epoch 39/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1045 - accuracy: 0.7666 - val_loss: 0.3631 - val_accuracy: 0.7725\n","Epoch 40/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1043 - accuracy: 0.7980 - val_loss: 0.3629 - val_accuracy: 0.7914\n","Epoch 41/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1042 - accuracy: 0.8039 - val_loss: 0.3628 - val_accuracy: 0.7869\n","Epoch 42/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1041 - accuracy: 0.7906 - val_loss: 0.3627 - val_accuracy: 0.7674\n","Epoch 43/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1039 - accuracy: 0.7352 - val_loss: 0.3625 - val_accuracy: 0.7818\n","Epoch 44/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1038 - accuracy: 0.7670 - val_loss: 0.3624 - val_accuracy: 0.7784\n","Epoch 45/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1037 - accuracy: 0.8010 - val_loss: 0.3622 - val_accuracy: 0.7666\n","Epoch 46/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1035 - accuracy: 0.7681 - val_loss: 0.3621 - val_accuracy: 0.7688\n","Epoch 47/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1034 - accuracy: 0.7278 - val_loss: 0.3620 - val_accuracy: 0.7541\n","Epoch 48/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1033 - accuracy: 0.7766 - val_loss: 0.3619 - val_accuracy: 0.7910\n","Epoch 49/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1032 - accuracy: 0.7891 - val_loss: 0.3618 - val_accuracy: 0.7736\n","Epoch 50/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1030 - accuracy: 0.7216 - val_loss: 0.3616 - val_accuracy: 0.7603\n","Epoch 51/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1029 - accuracy: 0.7943 - val_loss: 0.3615 - val_accuracy: 0.7729\n","Epoch 52/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1028 - accuracy: 0.7670 - val_loss: 0.3614 - val_accuracy: 0.7744\n","Epoch 53/300\n","2708/2708 [==============================] - 0s 105us/sample - loss: 0.1027 - accuracy: 0.7507 - val_loss: 0.3613 - val_accuracy: 0.7880\n","Epoch 54/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1026 - accuracy: 0.7773 - val_loss: 0.3612 - val_accuracy: 0.7810\n","Epoch 55/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1025 - accuracy: 0.7862 - val_loss: 0.3612 - val_accuracy: 0.7899\n","Epoch 56/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1025 - accuracy: 0.7570 - val_loss: 0.3611 - val_accuracy: 0.7973\n","Epoch 57/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1024 - accuracy: 0.7493 - val_loss: 0.3610 - val_accuracy: 0.7869\n","Epoch 58/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1023 - accuracy: 0.7710 - val_loss: 0.3609 - val_accuracy: 0.7910\n","Epoch 59/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1023 - accuracy: 0.7666 - val_loss: 0.3609 - val_accuracy: 0.8024\n","Epoch 60/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1022 - accuracy: 0.7456 - val_loss: 0.3608 - val_accuracy: 0.7987\n","Epoch 61/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1021 - accuracy: 0.7843 - val_loss: 0.3608 - val_accuracy: 0.8050\n","Epoch 62/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1021 - accuracy: 0.8013 - val_loss: 0.3607 - val_accuracy: 0.8183\n","Epoch 63/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1020 - accuracy: 0.8479 - val_loss: 0.3607 - val_accuracy: 0.8198\n","Epoch 64/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1020 - accuracy: 0.8519 - val_loss: 0.3606 - val_accuracy: 0.8220\n","Epoch 65/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1019 - accuracy: 0.7607 - val_loss: 0.3605 - val_accuracy: 0.8205\n","Epoch 66/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1019 - accuracy: 0.8423 - val_loss: 0.3605 - val_accuracy: 0.8154\n","Epoch 67/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1018 - accuracy: 0.8312 - val_loss: 0.3604 - val_accuracy: 0.8264\n","Epoch 68/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1018 - accuracy: 0.8043 - val_loss: 0.3604 - val_accuracy: 0.8320\n","Epoch 69/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1017 - accuracy: 0.8124 - val_loss: 0.3604 - val_accuracy: 0.8287\n","Epoch 70/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1017 - accuracy: 0.8434 - val_loss: 0.3603 - val_accuracy: 0.8242\n","Epoch 71/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1016 - accuracy: 0.8272 - val_loss: 0.3603 - val_accuracy: 0.8312\n","Epoch 72/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1016 - accuracy: 0.7962 - val_loss: 0.3602 - val_accuracy: 0.8312\n","Epoch 73/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1015 - accuracy: 0.8287 - val_loss: 0.3602 - val_accuracy: 0.8220\n","Epoch 74/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1015 - accuracy: 0.7991 - val_loss: 0.3602 - val_accuracy: 0.8323\n","Epoch 75/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1015 - accuracy: 0.8730 - val_loss: 0.3601 - val_accuracy: 0.8353\n","Epoch 76/300\n","2708/2708 [==============================] - 0s 99us/sample - loss: 0.1014 - accuracy: 0.8593 - val_loss: 0.3601 - val_accuracy: 0.8349\n","Epoch 77/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1014 - accuracy: 0.8785 - val_loss: 0.3601 - val_accuracy: 0.8375\n","Epoch 78/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1014 - accuracy: 0.8792 - val_loss: 0.3600 - val_accuracy: 0.8375\n","Epoch 79/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1013 - accuracy: 0.8874 - val_loss: 0.3600 - val_accuracy: 0.8379\n","Epoch 80/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1013 - accuracy: 0.8959 - val_loss: 0.3600 - val_accuracy: 0.8379\n","Epoch 81/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1013 - accuracy: 0.8840 - val_loss: 0.3599 - val_accuracy: 0.8379\n","Epoch 82/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1013 - accuracy: 0.9007 - val_loss: 0.3599 - val_accuracy: 0.8379\n","Epoch 83/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1012 - accuracy: 0.8881 - val_loss: 0.3599 - val_accuracy: 0.8379\n","Epoch 84/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1012 - accuracy: 0.9258 - val_loss: 0.3599 - val_accuracy: 0.8379\n","Epoch 85/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1012 - accuracy: 0.9173 - val_loss: 0.3598 - val_accuracy: 0.8379\n","Epoch 86/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1012 - accuracy: 0.9365 - val_loss: 0.3598 - val_accuracy: 0.8379\n","Epoch 87/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1011 - accuracy: 0.9243 - val_loss: 0.3598 - val_accuracy: 0.8379\n","Epoch 88/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1011 - accuracy: 0.9357 - val_loss: 0.3598 - val_accuracy: 0.8379\n","Epoch 89/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1011 - accuracy: 0.9317 - val_loss: 0.3598 - val_accuracy: 0.8379\n","Epoch 90/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1011 - accuracy: 0.8914 - val_loss: 0.3597 - val_accuracy: 0.8379\n","Epoch 91/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1011 - accuracy: 0.9162 - val_loss: 0.3597 - val_accuracy: 0.8379\n","Epoch 92/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1010 - accuracy: 0.9058 - val_loss: 0.3597 - val_accuracy: 0.8379\n","Epoch 93/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1010 - accuracy: 0.9103 - val_loss: 0.3597 - val_accuracy: 0.8379\n","Epoch 94/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1010 - accuracy: 0.8944 - val_loss: 0.3597 - val_accuracy: 0.8379\n","Epoch 95/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1010 - accuracy: 0.8597 - val_loss: 0.3597 - val_accuracy: 0.8379\n","Epoch 96/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1010 - accuracy: 0.9025 - val_loss: 0.3596 - val_accuracy: 0.8379\n","Epoch 97/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1010 - accuracy: 0.8696 - val_loss: 0.3596 - val_accuracy: 0.8379\n","Epoch 98/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1009 - accuracy: 0.9044 - val_loss: 0.3596 - val_accuracy: 0.8379\n","Epoch 99/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1009 - accuracy: 0.8600 - val_loss: 0.3596 - val_accuracy: 0.8379\n","Epoch 100/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1009 - accuracy: 0.8464 - val_loss: 0.3596 - val_accuracy: 0.8379\n","Epoch 101/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1009 - accuracy: 0.8767 - val_loss: 0.3596 - val_accuracy: 0.8379\n","Epoch 102/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1009 - accuracy: 0.8456 - val_loss: 0.3596 - val_accuracy: 0.8375\n","Epoch 103/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1009 - accuracy: 0.8290 - val_loss: 0.3596 - val_accuracy: 0.8379\n","Epoch 104/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1009 - accuracy: 0.8811 - val_loss: 0.3595 - val_accuracy: 0.8379\n","Epoch 105/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1009 - accuracy: 0.8434 - val_loss: 0.3595 - val_accuracy: 0.8379\n","Epoch 106/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1008 - accuracy: 0.8818 - val_loss: 0.3595 - val_accuracy: 0.8379\n","Epoch 107/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1008 - accuracy: 0.9007 - val_loss: 0.3595 - val_accuracy: 0.8379\n","Epoch 108/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1008 - accuracy: 0.8309 - val_loss: 0.3595 - val_accuracy: 0.8379\n","Epoch 109/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1008 - accuracy: 0.8316 - val_loss: 0.3595 - val_accuracy: 0.8379\n","Epoch 110/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1008 - accuracy: 0.8833 - val_loss: 0.3595 - val_accuracy: 0.8379\n","Epoch 111/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1008 - accuracy: 0.8379 - val_loss: 0.3595 - val_accuracy: 0.8379\n","Epoch 112/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1008 - accuracy: 0.8730 - val_loss: 0.3595 - val_accuracy: 0.8379\n","Epoch 113/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1008 - accuracy: 0.8194 - val_loss: 0.3595 - val_accuracy: 0.8379\n","Epoch 114/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1008 - accuracy: 0.8379 - val_loss: 0.3595 - val_accuracy: 0.8379\n","Epoch 115/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1008 - accuracy: 0.8855 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 116/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1008 - accuracy: 0.8527 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 117/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1008 - accuracy: 0.8597 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 118/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1007 - accuracy: 0.8179 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 119/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1007 - accuracy: 0.8128 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 120/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1007 - accuracy: 0.8475 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 121/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1007 - accuracy: 0.8449 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 122/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1007 - accuracy: 0.8360 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 123/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1007 - accuracy: 0.8663 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 124/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1007 - accuracy: 0.8988 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 125/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1007 - accuracy: 0.9073 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 126/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1007 - accuracy: 0.9095 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 127/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1007 - accuracy: 0.9287 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 128/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1007 - accuracy: 0.9250 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 129/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1007 - accuracy: 0.9151 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 130/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1007 - accuracy: 0.9180 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 131/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1007 - accuracy: 0.9298 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 132/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1007 - accuracy: 0.9250 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 133/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1007 - accuracy: 0.9265 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 134/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1007 - accuracy: 0.9099 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 135/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1007 - accuracy: 0.9051 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 136/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1007 - accuracy: 0.9092 - val_loss: 0.3594 - val_accuracy: 0.8379\n","Epoch 137/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1007 - accuracy: 0.9114 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 138/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1007 - accuracy: 0.9114 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 139/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1007 - accuracy: 0.9036 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 140/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1007 - accuracy: 0.9140 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 141/300\n","2708/2708 [==============================] - 0s 105us/sample - loss: 0.1007 - accuracy: 0.8922 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 142/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1007 - accuracy: 0.9077 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 143/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.8781 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 144/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.8999 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 145/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.8966 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 146/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.8593 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 147/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9099 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 148/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.8970 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 149/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9147 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 150/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.8907 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 151/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9346 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 152/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9258 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 153/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9442 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 154/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9376 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 155/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9365 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 156/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9520 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 157/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9405 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 158/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1006 - accuracy: 0.9476 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 159/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9490 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 160/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1006 - accuracy: 0.9498 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 161/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9549 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 162/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9538 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 163/300\n","2708/2708 [==============================] - 0s 105us/sample - loss: 0.1006 - accuracy: 0.9538 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 164/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9542 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 165/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9549 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 166/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9546 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 167/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 168/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9549 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 169/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1006 - accuracy: 0.9549 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 170/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1006 - accuracy: 0.9553 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 171/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9553 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 172/300\n","2708/2708 [==============================] - 0s 99us/sample - loss: 0.1006 - accuracy: 0.9549 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 173/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 174/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1006 - accuracy: 0.9561 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 175/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 176/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 177/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 178/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 179/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1006 - accuracy: 0.9553 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 180/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 181/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9553 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 182/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9553 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 183/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9535 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 184/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 185/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9549 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 186/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9553 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 187/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9538 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 188/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9535 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 189/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9524 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 190/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1006 - accuracy: 0.9538 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 191/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9535 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 192/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 193/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9531 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 194/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1006 - accuracy: 0.9542 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 195/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9531 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 196/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9535 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 197/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 198/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 199/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9553 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 200/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 201/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9561 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 202/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 203/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 204/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 205/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 206/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 207/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 208/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 209/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 210/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 211/300\n","2708/2708 [==============================] - 0s 105us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 212/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 213/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 214/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8375\n","Epoch 215/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8375\n","Epoch 216/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8375\n","Epoch 217/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9561 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 218/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9549 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 219/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 220/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 221/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 222/300\n","2708/2708 [==============================] - 0s 105us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 223/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 224/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 225/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 226/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 227/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 228/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 229/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 230/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 231/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 232/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 233/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 234/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 235/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 236/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 237/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 238/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 239/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 240/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 241/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 242/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 243/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 244/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 245/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 246/300\n","2708/2708 [==============================] - 0s 99us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 247/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 248/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 249/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 250/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 251/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 252/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 253/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 254/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 255/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 256/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 257/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 258/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 259/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 260/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 261/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 262/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 263/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 264/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 265/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 266/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 267/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 268/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 269/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 270/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 271/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 272/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 273/300\n","2708/2708 [==============================] - 0s 105us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 274/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 275/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 276/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 277/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 278/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 279/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 280/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 281/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 282/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 283/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 284/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 285/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 286/300\n","2708/2708 [==============================] - 0s 100us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 287/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 288/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 289/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 290/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 291/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 292/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 293/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 294/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 295/300\n","2708/2708 [==============================] - 0s 104us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 296/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 297/300\n","2708/2708 [==============================] - 0s 101us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 298/300\n","2708/2708 [==============================] - 0s 103us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 299/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n","Epoch 300/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.9557 - val_loss: 0.3593 - val_accuracy: 0.8379\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fcff9fb74e0>"]},"metadata":{"tags":[]},"execution_count":115}]}]}