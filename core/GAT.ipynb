{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAT.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"7HPxbz9IZ1xO","colab_type":"code","colab":{}},"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kIH9phOegalY","colab_type":"code","colab":{}},"cell_type":"code","source":["from __future__ import absolute_import, division, print_function\n","\n","!pip install tensorflow-gpu==2.0.0-alpha0\n","import tensorflow_datasets as tfds\n","import tensorflow as tf\n","\n","from tensorflow.keras import activations\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Layer, Input, Dense, Activation, Dropout, LeakyReLU, Softmax, ReLU\n","from tensorflow.keras import Model\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5PIfldx7gczn","colab_type":"code","colab":{}},"cell_type":"code","source":["import os,sys,inspect\n","import os\n","import joblib\n","import tensorflow as tf\n","import numpy as np\n","import h5py\n","import scipy.sparse.linalg as la\n","import scipy.sparse as sp\n","import scipy\n","import time\n","import pickle\n","\n","import matplotlib.pyplot as plt\n","from matplotlib.backends.backend_pdf import PdfPages\n","%matplotlib inline\n","\n","import scipy.io as sio\n","import process_data\n","\n","from google.colab import files"],"execution_count":0,"outputs":[]},{"metadata":{"id":"--__rXD2u_HM","colab_type":"code","colab":{}},"cell_type":"code","source":["def convert_coo_to_sparse_tensor(L):\n","    indices = np.column_stack((L.row, L.col))\n","    L = tf.SparseTensor(indices, L.data.astype('float32'), L.shape)\n","    L = tf.sparse.reorder(L)\n","    return L"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GA_7oCF3iSuG","colab_type":"code","colab":{}},"cell_type":"code","source":["# Load dataset from local\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))\n"," "],"execution_count":0,"outputs":[]},{"metadata":{"id":"WQ16sP9CKMDg","colab_type":"code","outputId":"94ab0ee6-13c9-48e7-f6d2-97c767c5989f","executionInfo":{"status":"ok","timestamp":1554805139507,"user_tz":-120,"elapsed":998,"user":{"displayName":"Alessia Ruggeri","photoUrl":"","userId":"01098494933204128714"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"cell_type":"code","source":["# Dataset loading\n","\n","A, X, Y, train_idx, val_idx, test_idx = process_data.load_data(\"cora\")\n","X = process_data.preprocess_features(X)\n","# A = convert_coo_to_sparse_tensor(A.tocoo())\n","A = A + np.eye(A.shape[0])  # Add self-loops\n","\n","x_train, y_train = X[train_idx], Y[train_idx]\n","x_val, y_val = X[val_idx], Y[val_idx]\n","x_test, y_test = X[test_idx], Y[test_idx]\n","\n","idx = np.zeros(shape=(X.shape[0],))\n","idx[train_idx] = 1\n","train_idx = idx\n","idx = np.zeros(shape=(X.shape[0],))\n","idx[val_idx] = 1\n","val_idx = idx\n","idx = np.zeros(shape=(X.shape[0],))\n","idx[test_idx] = 1\n","test_idx = idx\n","\n","print(\"x_train\\t\", x_train.shape)\n","print(\"y_train\\t\", y_train.shape)\n","print(\"x_val\\t\", x_val.shape)\n","print(\"y_val\\t\", y_val.shape)\n","print(\"x_test\\t\", x_test.shape)\n","print(\"y_test\\t\", y_test.shape)\n","\n","# mask = tf.equal(A.indices[:, 0], 0)\n","# print(mask)\n","# tf.boolean_mask(A.indices, mask)\n","\n","# A_train = tf.sparse.to_dense(tf.sparse.slice(A,\n","#                                              start=[0,0],\n","#                                              size=[len(train_idx), len(train_idx)]))\n","# A_val = tf.sparse.to_dense(tf.sparse.slice(A,\n","#                                            start=[len(train_idx), len(train_idx)],\n","#                                            size=[len(val_idx), len(val_idx)]))\n","# A_test = tf.sparse.to_dense(tf.sparse.slice(A,\n","#                                             start=[len(train_idx)+len(val_idx), len(train_idx)+len(val_idx)],\n","#                                             size=[len(test_idx), len(test_idx)]))\n","\n","# A_train = A[0:len(train_idx),\n","#             0:len(train_idx)]\n","# A_val = A[len(train_idx):len(train_idx)+len(val_idx),\n","#                           len(train_idx):len(train_idx)+len(val_idx)]\n","# A_test = A[len(train_idx)+len(val_idx):len(train_idx)+len(val_idx)+len(test_idx),\n","#            len(train_idx)+len(val_idx):len(train_idx)+len(val_idx)+len(test_idx)]"],"execution_count":65,"outputs":[{"output_type":"stream","text":["(2708, 2708)\n","(2708, 1433)\n","x_train\t (140, 1433)\n","y_train\t (140, 7)\n","x_val\t (500, 1433)\n","y_val\t (500, 7)\n","x_test\t (1000, 1433)\n","y_test\t (1000, 7)\n"],"name":"stdout"}]},{"metadata":{"id":"jAIiv6gtLoNS","colab_type":"code","colab":{}},"cell_type":"code","source":["# x = np.random.rand(10,1)\n","# y = np.random.rand(10,1)\n","\n","# # x = np.reshape(x, (1, 1, 2))\n","# # y = np.reshape(y, (1, 1, 2))\n","\n","# # x = np.transpose(x)\n","# y = np.transpose(y)\n","\n","# print(x)\n","# print(y)\n","\n","# z = x + y\n","# z"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q6pFS8zhsZBs","colab_type":"code","colab":{}},"cell_type":"code","source":["### ONE INPUT VERSION ###\n","\n","\n","# Create attention\n","\n","class Attention(Layer):\n","  \n","  def __init__(self, F_1, A, train_idx, **kwargs):\n","    self.F_1 = F_1\n","    self.train_idx = len(train_idx)\n","    self.A = tf.sparse.slice(A, start=[0,0], size=[self.train_idx, self.train_idx])\n","    self.A = tf.sparse.to_dense(self.A)\n","    super(Attention, self).__init__(**kwargs)\n","\n","  def build(self, input_shape):\n","    F = input_shape[-1]\n","    self.W = self.add_weight(name='W', \n","                             shape=(self.F_1, F),\n","                             initializer='uniform',\n","                             trainable=True)\n","\n","    self.a = self.add_weight(name='a', \n","                             shape=(2, self.F_1, 1),\n","                             initializer='uniform',\n","                             trainable=True)\n","\n","    super(Attention, self).build(input_shape)  # Be sure to call this at the end\n","   \n","  def call(self, inputs):\n","    X = inputs\n","\n","    x_features = X @ tf.transpose(self.W)\n","#     x_features = (N, F_1)\n","    att_self = x_features @ self.a[0]\n","    att_neighbours = x_features @ self.a[1]\n","#     both att = (N, 1)\n","    att = att_self + tf.transpose(att_neighbours)\n","#     att = (N, N)\n","    att = LeakyReLU(alpha=0.2)(att)\n","  \n","    mask = -10e9 * (1.0 - self.A)\n","    att_masked = att + mask\n","#     att_masked = att * A\n","    dense = Softmax(axis=0)(att_masked)\n","#     dense = (N, N)\n","    dense = dense @ x_features\n","#     dense = (N, F_1)\n","\n","    return dense\n","\n","  def compute_output_shape(self, input_shape):\n","    return (input_shape, self.output_dim)\n","    \n","\n","\n","# Create Gaussian (kernel) layer\n","\n","class GAT(Layer):\n","  \n","  def __init__(self, F_1, K, A, train_idx, last=False, **kwargs):\n","    self.F_1 = F_1\n","    self.K = K\n","    self.train_idx = train_idx\n","    self.A = A\n","    self.last = last\n","    self.attentions = []\n","    for k in range(self.K):\n","      attention = Attention(self.F_1, A, train_idx)\n","      self.attentions.append(attention)\n","    super(GAT, self).__init__(**kwargs)\n","  \n","  def build(self, input_shape):\n","\n","    super(GAT, self).build(input_shape)  # Be sure to call this at the end\n","   \n","  def call(self, inputs):\n","    X = inputs\n","\n","    attentions = []\n","    for k in range(self.K):\n","      attention = self.attentions[k](X)\n","      attentions.append(attention)\n","\n","    if self.last:\n","#       h = (N, F_1)\n","      h = tf.reduce_mean(tf.stack(attentions), axis=0)\n","      h = Softmax()(h)\n","    else:\n","#       h = (N, F_1*k)\n","      h = tf.concat(attentions, axis=1)\n","      h = ReLU()(h)\n","    \n","    return h\n","\n","  def compute_output_shape(self, input_shape):\n","    return (input_shape, self.output_dim)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"u7T_7pdr5TyA","colab_type":"code","colab":{}},"cell_type":"code","source":["print(x_train.shape)\n","h = GAT(8, 8, A=A, train_idx=train_idx, last=False, input_shape=(X.shape[-1],))(x_train)\n","h = GAT(7, 2, A=A, train_idx=train_idx, last=True, input_shape=(h.shape[-1],))(h)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kLFKdvEjuszj","colab_type":"code","colab":{}},"cell_type":"code","source":["### ONE INPUT VERSION ###\n","\n","epochs=1000\n","batch_size = x_train.shape[0]\n","n_classes = 7\n","F_1 = 8\n","K = 8\n","\n","model = Sequential()\n","model.add(GAT(F_1=F_1, K=K, A=A, train_idx=train_idx, last=False, input_shape=(x_train.shape[-1],)))\n","model.add(GAT(F_1=n_classes, K=1, A=A, train_idx=train_idx, last=True))\n","\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# print(model.summary())\n","model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, shuffle=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W0Sks2femqFP","colab_type":"code","colab":{}},"cell_type":"code","source":["### TWO INPUT VERSION ###\n","\n","\n","# Create attention\n","\n","class Attention(Layer):\n","  \n","  def __init__(self, F_1, **kwargs):\n","    self.F_1 = F_1\n","    super(Attention, self).__init__(**kwargs)\n","\n","  def build(self, input_shape):\n","    F = input_shape[0][-1]\n","    self.W = self.add_weight(name='W', \n","                             shape=(self.F_1, F),\n","                             initializer='uniform',\n","                             trainable=True)\n","\n","    self.a = self.add_weight(name='a', \n","                             shape=(2, self.F_1, 1),\n","                             initializer='uniform',\n","                             trainable=True)\n","\n","    super(Attention, self).build(input_shape)  # Be sure to call this at the end\n","   \n","  def call(self, inputs):\n","    X = inputs[0]\n","    A = inputs[1]\n","    dropout = 0.3\n","\n","    x_features = X @ tf.transpose(self.W)\n","#     x_features = (N, F_1)\n","    att_self = x_features @ self.a[0]\n","    att_neighbours = x_features @ self.a[1]\n","#     both att = (N, 1)\n","    att = att_self + tf.transpose(att_neighbours)\n","#     att = (N, N)\n","    att = LeakyReLU(alpha=0.2)(att)\n","\n","    mask = -10e9 * (1.0 - A)\n","    att_masked = att + mask\n","#     att_masked = att * A\n","    dense = Softmax(axis=0)(att_masked)\n","  \n","#     dense = Dropout(dropout)(dense)\n","#     x_features = Dropout(dropout)(x_features)\n","    \n","#     dense = (N, N)\n","    dense = dense @ x_features\n","#     dense = (N, F_1)\n","\n","    return dense\n","\n","  def compute_output_shape(self, input_shape):\n","    return (input_shape[0][0], self.output_dim)\n","    \n","\n","\n","# Create Gaussian (kernel) layer\n","\n","class GAT(Layer):\n","  \n","  def __init__(self, F_1, K, last=False, **kwargs):\n","    self.F_1 = F_1\n","    self.K = K\n","    self.last = last\n","    self.attentions = []\n","    for k in range(self.K):\n","      attention = Attention(self.F_1)\n","      self.attentions.append(attention)\n","    super(GAT, self).__init__(**kwargs)\n","  \n","  def build(self, input_shape):\n","\n","    super(GAT, self).build(input_shape)  # Be sure to call this at the end\n","   \n","  def call(self, inputs):\n","    X = inputs[0]\n","    A = inputs[1]\n","\n","    attentions = []\n","    for k in range(self.K):\n","      attention = self.attentions[k]([X, A])\n","      attentions.append(attention)\n","\n","    if self.last:\n","#       h = (N, F_1)\n","      h = tf.reduce_mean(tf.stack(attentions), axis=0)\n","      h = Softmax()(h)\n","    else:\n","#       h = (N, F_1*k)\n","      h = tf.concat(attentions, axis=1)\n","      h = ReLU()(h)\n","    return h\n","\n","  def compute_output_shape(self, input_shape):\n","    return (input_shape[0][0], self.output_dim)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZvV6rS1omqVA","colab_type":"code","outputId":"a0a47c1c-180b-4b9d-c7af-ceed1af8aab0","executionInfo":{"status":"ok","timestamp":1554805369207,"user_tz":-120,"elapsed":83098,"user":{"displayName":"Alessia Ruggeri","photoUrl":"","userId":"01098494933204128714"}},"colab":{"base_uri":"https://localhost:8080/","height":10251}},"cell_type":"code","source":["### TWO INPUT VERSION ###\n","\n","epochs=300\n","batch_size = X.shape[0]\n","# batch_size = 20\n","n_classes = 7\n","F_1 = 8\n","K = 8\n","\n","X_in = Input(shape=(X.shape[-1],))\n","A_in = Input(shape=(batch_size,))\n","\n","layer1 = GAT(F_1=F_1, K=K, last=False, input_shape=(X.shape[-1],))([X_in, A_in])\n","layer2 = GAT(F_1=n_classes, K=1, last=True)([layer1, A_in])\n","\n","model = Model(inputs=[X_in, A_in], outputs=layer2)\n","\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              weighted_metrics=['accuracy'])\n","# print(model.summary())\n","\n","validation_data = ([X, A], Y, val_idx)\n","model.fit([X, A], Y, validation_data=validation_data, sample_weight=train_idx, epochs=epochs, batch_size=batch_size, shuffle=False)"],"execution_count":67,"outputs":[{"output_type":"stream","text":["Train on 2708 samples, validate on 2708 samples\n","Epoch 1/300\n","2708/2708 [==============================] - 1s 547us/sample - loss: 0.1006 - accuracy: 0.1500 - val_loss: 0.3593 - val_accuracy: 0.1420\n","Epoch 2/300\n","2708/2708 [==============================] - 0s 109us/sample - loss: 0.1006 - accuracy: 0.2000 - val_loss: 0.3593 - val_accuracy: 0.1500\n","Epoch 3/300\n","2708/2708 [==============================] - 0s 102us/sample - loss: 0.1006 - accuracy: 0.2571 - val_loss: 0.3593 - val_accuracy: 0.1200\n","Epoch 4/300\n","2708/2708 [==============================] - 0s 96us/sample - loss: 0.1006 - accuracy: 0.3500 - val_loss: 0.3593 - val_accuracy: 0.1440\n","Epoch 5/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.1006 - accuracy: 0.4286 - val_loss: 0.3593 - val_accuracy: 0.1220\n","Epoch 6/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.1006 - accuracy: 0.5143 - val_loss: 0.3593 - val_accuracy: 0.1460\n","Epoch 7/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.1006 - accuracy: 0.5929 - val_loss: 0.3593 - val_accuracy: 0.1320\n","Epoch 8/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.1006 - accuracy: 0.6214 - val_loss: 0.3593 - val_accuracy: 0.1420\n","Epoch 9/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.1005 - accuracy: 0.6714 - val_loss: 0.3593 - val_accuracy: 0.1540\n","Epoch 10/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.1005 - accuracy: 0.6786 - val_loss: 0.3593 - val_accuracy: 0.1360\n","Epoch 11/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.1005 - accuracy: 0.7000 - val_loss: 0.3593 - val_accuracy: 0.1440\n","Epoch 12/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.1005 - accuracy: 0.7357 - val_loss: 0.3593 - val_accuracy: 0.1340\n","Epoch 13/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.1005 - accuracy: 0.7714 - val_loss: 0.3593 - val_accuracy: 0.1300\n","Epoch 14/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.1005 - accuracy: 0.7714 - val_loss: 0.3593 - val_accuracy: 0.1340\n","Epoch 15/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.1005 - accuracy: 0.7857 - val_loss: 0.3593 - val_accuracy: 0.1460\n","Epoch 16/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.1005 - accuracy: 0.8000 - val_loss: 0.3593 - val_accuracy: 0.1380\n","Epoch 17/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.1005 - accuracy: 0.8000 - val_loss: 0.3593 - val_accuracy: 0.1400\n","Epoch 18/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.1004 - accuracy: 0.8143 - val_loss: 0.3593 - val_accuracy: 0.1260\n","Epoch 19/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.1004 - accuracy: 0.8214 - val_loss: 0.3593 - val_accuracy: 0.1300\n","Epoch 20/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.1004 - accuracy: 0.8214 - val_loss: 0.3593 - val_accuracy: 0.1380\n","Epoch 21/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.1004 - accuracy: 0.8214 - val_loss: 0.3593 - val_accuracy: 0.1300\n","Epoch 22/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.1004 - accuracy: 0.8214 - val_loss: 0.3593 - val_accuracy: 0.1300\n","Epoch 23/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.1003 - accuracy: 0.8214 - val_loss: 0.3593 - val_accuracy: 0.1200\n","Epoch 24/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.1003 - accuracy: 0.8214 - val_loss: 0.3593 - val_accuracy: 0.1180\n","Epoch 25/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.1003 - accuracy: 0.8214 - val_loss: 0.3593 - val_accuracy: 0.1360\n","Epoch 26/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.1003 - accuracy: 0.8286 - val_loss: 0.3593 - val_accuracy: 0.1300\n","Epoch 27/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.1002 - accuracy: 0.8429 - val_loss: 0.3593 - val_accuracy: 0.1520\n","Epoch 28/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.1002 - accuracy: 0.8429 - val_loss: 0.3593 - val_accuracy: 0.1240\n","Epoch 29/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.1002 - accuracy: 0.8500 - val_loss: 0.3593 - val_accuracy: 0.1300\n","Epoch 30/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.1001 - accuracy: 0.8500 - val_loss: 0.3592 - val_accuracy: 0.1400\n","Epoch 31/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.1001 - accuracy: 0.8500 - val_loss: 0.3593 - val_accuracy: 0.1380\n","Epoch 32/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.1000 - accuracy: 0.8500 - val_loss: 0.3593 - val_accuracy: 0.1220\n","Epoch 33/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.1000 - accuracy: 0.8500 - val_loss: 0.3593 - val_accuracy: 0.1160\n","Epoch 34/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.1000 - accuracy: 0.8429 - val_loss: 0.3593 - val_accuracy: 0.1260\n","Epoch 35/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0999 - accuracy: 0.8429 - val_loss: 0.3592 - val_accuracy: 0.1260\n","Epoch 36/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0999 - accuracy: 0.8429 - val_loss: 0.3592 - val_accuracy: 0.1420\n","Epoch 37/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0998 - accuracy: 0.8429 - val_loss: 0.3592 - val_accuracy: 0.1340\n","Epoch 38/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0998 - accuracy: 0.8357 - val_loss: 0.3592 - val_accuracy: 0.1340\n","Epoch 39/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0997 - accuracy: 0.8214 - val_loss: 0.3593 - val_accuracy: 0.1300\n","Epoch 40/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0996 - accuracy: 0.8214 - val_loss: 0.3591 - val_accuracy: 0.1340\n","Epoch 41/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0996 - accuracy: 0.8214 - val_loss: 0.3592 - val_accuracy: 0.1300\n","Epoch 42/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0995 - accuracy: 0.8214 - val_loss: 0.3592 - val_accuracy: 0.1160\n","Epoch 43/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0994 - accuracy: 0.8143 - val_loss: 0.3593 - val_accuracy: 0.1260\n","Epoch 44/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0994 - accuracy: 0.8143 - val_loss: 0.3592 - val_accuracy: 0.1300\n","Epoch 45/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0993 - accuracy: 0.8143 - val_loss: 0.3592 - val_accuracy: 0.1300\n","Epoch 46/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0992 - accuracy: 0.8143 - val_loss: 0.3592 - val_accuracy: 0.1300\n","Epoch 47/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0991 - accuracy: 0.8214 - val_loss: 0.3590 - val_accuracy: 0.1380\n","Epoch 48/300\n","2708/2708 [==============================] - 0s 91us/sample - loss: 0.0990 - accuracy: 0.8214 - val_loss: 0.3592 - val_accuracy: 0.1260\n","Epoch 49/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0989 - accuracy: 0.8286 - val_loss: 0.3591 - val_accuracy: 0.1180\n","Epoch 50/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0988 - accuracy: 0.8286 - val_loss: 0.3592 - val_accuracy: 0.1200\n","Epoch 51/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0987 - accuracy: 0.8286 - val_loss: 0.3593 - val_accuracy: 0.1280\n","Epoch 52/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0986 - accuracy: 0.8286 - val_loss: 0.3591 - val_accuracy: 0.1380\n","Epoch 53/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0985 - accuracy: 0.8286 - val_loss: 0.3591 - val_accuracy: 0.1220\n","Epoch 54/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0984 - accuracy: 0.8286 - val_loss: 0.3591 - val_accuracy: 0.1340\n","Epoch 55/300\n","2708/2708 [==============================] - 0s 91us/sample - loss: 0.0983 - accuracy: 0.8357 - val_loss: 0.3590 - val_accuracy: 0.1340\n","Epoch 56/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0982 - accuracy: 0.8357 - val_loss: 0.3591 - val_accuracy: 0.1280\n","Epoch 57/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0981 - accuracy: 0.8357 - val_loss: 0.3590 - val_accuracy: 0.1340\n","Epoch 58/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0980 - accuracy: 0.8357 - val_loss: 0.3591 - val_accuracy: 0.1320\n","Epoch 59/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0978 - accuracy: 0.8357 - val_loss: 0.3591 - val_accuracy: 0.1220\n","Epoch 60/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0977 - accuracy: 0.8357 - val_loss: 0.3592 - val_accuracy: 0.1280\n","Epoch 61/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0976 - accuracy: 0.8357 - val_loss: 0.3590 - val_accuracy: 0.1200\n","Epoch 62/300\n","2708/2708 [==============================] - 0s 96us/sample - loss: 0.0974 - accuracy: 0.8429 - val_loss: 0.3590 - val_accuracy: 0.1240\n","Epoch 63/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0973 - accuracy: 0.8429 - val_loss: 0.3593 - val_accuracy: 0.1240\n","Epoch 64/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0971 - accuracy: 0.8429 - val_loss: 0.3589 - val_accuracy: 0.1320\n","Epoch 65/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0970 - accuracy: 0.8500 - val_loss: 0.3592 - val_accuracy: 0.1360\n","Epoch 66/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0968 - accuracy: 0.8500 - val_loss: 0.3588 - val_accuracy: 0.1260\n","Epoch 67/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0967 - accuracy: 0.8500 - val_loss: 0.3591 - val_accuracy: 0.1300\n","Epoch 68/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0965 - accuracy: 0.8500 - val_loss: 0.3589 - val_accuracy: 0.1240\n","Epoch 69/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0963 - accuracy: 0.8500 - val_loss: 0.3587 - val_accuracy: 0.1300\n","Epoch 70/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0961 - accuracy: 0.8500 - val_loss: 0.3589 - val_accuracy: 0.1280\n","Epoch 71/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0960 - accuracy: 0.8500 - val_loss: 0.3591 - val_accuracy: 0.1220\n","Epoch 72/300\n","2708/2708 [==============================] - 0s 97us/sample - loss: 0.0958 - accuracy: 0.8500 - val_loss: 0.3590 - val_accuracy: 0.1180\n","Epoch 73/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0956 - accuracy: 0.8571 - val_loss: 0.3590 - val_accuracy: 0.1320\n","Epoch 74/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0954 - accuracy: 0.8571 - val_loss: 0.3589 - val_accuracy: 0.1240\n","Epoch 75/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0952 - accuracy: 0.8571 - val_loss: 0.3591 - val_accuracy: 0.1400\n","Epoch 76/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0950 - accuracy: 0.8571 - val_loss: 0.3586 - val_accuracy: 0.1420\n","Epoch 77/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0948 - accuracy: 0.8571 - val_loss: 0.3589 - val_accuracy: 0.1220\n","Epoch 78/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0946 - accuracy: 0.8571 - val_loss: 0.3591 - val_accuracy: 0.1240\n","Epoch 79/300\n","2708/2708 [==============================] - 0s 91us/sample - loss: 0.0944 - accuracy: 0.8571 - val_loss: 0.3588 - val_accuracy: 0.1380\n","Epoch 80/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0942 - accuracy: 0.8571 - val_loss: 0.3585 - val_accuracy: 0.1180\n","Epoch 81/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0939 - accuracy: 0.8571 - val_loss: 0.3588 - val_accuracy: 0.1280\n","Epoch 82/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0937 - accuracy: 0.8571 - val_loss: 0.3586 - val_accuracy: 0.1420\n","Epoch 83/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0935 - accuracy: 0.8571 - val_loss: 0.3590 - val_accuracy: 0.1220\n","Epoch 84/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0932 - accuracy: 0.8643 - val_loss: 0.3586 - val_accuracy: 0.1340\n","Epoch 85/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0930 - accuracy: 0.8714 - val_loss: 0.3589 - val_accuracy: 0.1300\n","Epoch 86/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0928 - accuracy: 0.8714 - val_loss: 0.3585 - val_accuracy: 0.1400\n","Epoch 87/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0925 - accuracy: 0.8714 - val_loss: 0.3588 - val_accuracy: 0.1240\n","Epoch 88/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0922 - accuracy: 0.8714 - val_loss: 0.3593 - val_accuracy: 0.1240\n","Epoch 89/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0920 - accuracy: 0.8714 - val_loss: 0.3587 - val_accuracy: 0.1340\n","Epoch 90/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0917 - accuracy: 0.8714 - val_loss: 0.3589 - val_accuracy: 0.1220\n","Epoch 91/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0915 - accuracy: 0.8714 - val_loss: 0.3589 - val_accuracy: 0.1320\n","Epoch 92/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0912 - accuracy: 0.8786 - val_loss: 0.3588 - val_accuracy: 0.1180\n","Epoch 93/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0909 - accuracy: 0.8786 - val_loss: 0.3591 - val_accuracy: 0.1460\n","Epoch 94/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0906 - accuracy: 0.8786 - val_loss: 0.3580 - val_accuracy: 0.1360\n","Epoch 95/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0904 - accuracy: 0.8786 - val_loss: 0.3589 - val_accuracy: 0.1400\n","Epoch 96/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0901 - accuracy: 0.8786 - val_loss: 0.3586 - val_accuracy: 0.1260\n","Epoch 97/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0898 - accuracy: 0.8786 - val_loss: 0.3580 - val_accuracy: 0.1360\n","Epoch 98/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0895 - accuracy: 0.8786 - val_loss: 0.3592 - val_accuracy: 0.1400\n","Epoch 99/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0892 - accuracy: 0.8929 - val_loss: 0.3590 - val_accuracy: 0.1320\n","Epoch 100/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0889 - accuracy: 0.8929 - val_loss: 0.3585 - val_accuracy: 0.1320\n","Epoch 101/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0886 - accuracy: 0.8929 - val_loss: 0.3588 - val_accuracy: 0.1280\n","Epoch 102/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0883 - accuracy: 0.9000 - val_loss: 0.3585 - val_accuracy: 0.1580\n","Epoch 103/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0879 - accuracy: 0.9000 - val_loss: 0.3588 - val_accuracy: 0.1260\n","Epoch 104/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0876 - accuracy: 0.9000 - val_loss: 0.3582 - val_accuracy: 0.1240\n","Epoch 105/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0873 - accuracy: 0.9000 - val_loss: 0.3589 - val_accuracy: 0.1360\n","Epoch 106/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0870 - accuracy: 0.9000 - val_loss: 0.3593 - val_accuracy: 0.1360\n","Epoch 107/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0867 - accuracy: 0.9000 - val_loss: 0.3579 - val_accuracy: 0.1280\n","Epoch 108/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0863 - accuracy: 0.9000 - val_loss: 0.3591 - val_accuracy: 0.1300\n","Epoch 109/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0860 - accuracy: 0.9000 - val_loss: 0.3586 - val_accuracy: 0.1400\n","Epoch 110/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0856 - accuracy: 0.9000 - val_loss: 0.3583 - val_accuracy: 0.1380\n","Epoch 111/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0853 - accuracy: 0.9071 - val_loss: 0.3575 - val_accuracy: 0.1500\n","Epoch 112/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0850 - accuracy: 0.9071 - val_loss: 0.3587 - val_accuracy: 0.1180\n","Epoch 113/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0846 - accuracy: 0.9071 - val_loss: 0.3581 - val_accuracy: 0.1500\n","Epoch 114/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0843 - accuracy: 0.9143 - val_loss: 0.3591 - val_accuracy: 0.1480\n","Epoch 115/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0839 - accuracy: 0.9143 - val_loss: 0.3581 - val_accuracy: 0.1260\n","Epoch 116/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0836 - accuracy: 0.9143 - val_loss: 0.3585 - val_accuracy: 0.1440\n","Epoch 117/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0832 - accuracy: 0.9143 - val_loss: 0.3584 - val_accuracy: 0.1360\n","Epoch 118/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0828 - accuracy: 0.9143 - val_loss: 0.3578 - val_accuracy: 0.1360\n","Epoch 119/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0825 - accuracy: 0.9214 - val_loss: 0.3578 - val_accuracy: 0.1500\n","Epoch 120/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0821 - accuracy: 0.9214 - val_loss: 0.3584 - val_accuracy: 0.1500\n","Epoch 121/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0817 - accuracy: 0.9214 - val_loss: 0.3583 - val_accuracy: 0.1620\n","Epoch 122/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0813 - accuracy: 0.9286 - val_loss: 0.3580 - val_accuracy: 0.1560\n","Epoch 123/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0810 - accuracy: 0.9286 - val_loss: 0.3585 - val_accuracy: 0.1260\n","Epoch 124/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0806 - accuracy: 0.9286 - val_loss: 0.3584 - val_accuracy: 0.1520\n","Epoch 125/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0802 - accuracy: 0.9357 - val_loss: 0.3571 - val_accuracy: 0.1320\n","Epoch 126/300\n","2708/2708 [==============================] - 0s 96us/sample - loss: 0.0798 - accuracy: 0.9357 - val_loss: 0.3580 - val_accuracy: 0.1460\n","Epoch 127/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0794 - accuracy: 0.9357 - val_loss: 0.3578 - val_accuracy: 0.1520\n","Epoch 128/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0790 - accuracy: 0.9429 - val_loss: 0.3575 - val_accuracy: 0.1540\n","Epoch 129/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0786 - accuracy: 0.9429 - val_loss: 0.3584 - val_accuracy: 0.1400\n","Epoch 130/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0782 - accuracy: 0.9500 - val_loss: 0.3585 - val_accuracy: 0.1580\n","Epoch 131/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0778 - accuracy: 0.9500 - val_loss: 0.3575 - val_accuracy: 0.1440\n","Epoch 132/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0774 - accuracy: 0.9500 - val_loss: 0.3584 - val_accuracy: 0.1500\n","Epoch 133/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0770 - accuracy: 0.9571 - val_loss: 0.3577 - val_accuracy: 0.1640\n","Epoch 134/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0766 - accuracy: 0.9571 - val_loss: 0.3571 - val_accuracy: 0.1680\n","Epoch 135/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0762 - accuracy: 0.9571 - val_loss: 0.3570 - val_accuracy: 0.1640\n","Epoch 136/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0758 - accuracy: 0.9571 - val_loss: 0.3572 - val_accuracy: 0.1800\n","Epoch 137/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0754 - accuracy: 0.9571 - val_loss: 0.3570 - val_accuracy: 0.1860\n","Epoch 138/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0750 - accuracy: 0.9571 - val_loss: 0.3575 - val_accuracy: 0.2040\n","Epoch 139/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0746 - accuracy: 0.9571 - val_loss: 0.3581 - val_accuracy: 0.1280\n","Epoch 140/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0741 - accuracy: 0.9571 - val_loss: 0.3571 - val_accuracy: 0.1880\n","Epoch 141/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0737 - accuracy: 0.9571 - val_loss: 0.3566 - val_accuracy: 0.1340\n","Epoch 142/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0733 - accuracy: 0.9571 - val_loss: 0.3581 - val_accuracy: 0.1520\n","Epoch 143/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0729 - accuracy: 0.9571 - val_loss: 0.3567 - val_accuracy: 0.1760\n","Epoch 144/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0725 - accuracy: 0.9571 - val_loss: 0.3577 - val_accuracy: 0.1640\n","Epoch 145/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0720 - accuracy: 0.9571 - val_loss: 0.3572 - val_accuracy: 0.1640\n","Epoch 146/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0716 - accuracy: 0.9571 - val_loss: 0.3555 - val_accuracy: 0.1780\n","Epoch 147/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0712 - accuracy: 0.9571 - val_loss: 0.3558 - val_accuracy: 0.1940\n","Epoch 148/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0708 - accuracy: 0.9571 - val_loss: 0.3563 - val_accuracy: 0.1760\n","Epoch 149/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0703 - accuracy: 0.9571 - val_loss: 0.3562 - val_accuracy: 0.1700\n","Epoch 150/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0699 - accuracy: 0.9571 - val_loss: 0.3555 - val_accuracy: 0.1820\n","Epoch 151/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0695 - accuracy: 0.9571 - val_loss: 0.3560 - val_accuracy: 0.2140\n","Epoch 152/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0690 - accuracy: 0.9571 - val_loss: 0.3555 - val_accuracy: 0.1860\n","Epoch 153/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0686 - accuracy: 0.9643 - val_loss: 0.3559 - val_accuracy: 0.1740\n","Epoch 154/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0682 - accuracy: 0.9643 - val_loss: 0.3572 - val_accuracy: 0.1680\n","Epoch 155/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0677 - accuracy: 0.9643 - val_loss: 0.3573 - val_accuracy: 0.1540\n","Epoch 156/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0673 - accuracy: 0.9643 - val_loss: 0.3554 - val_accuracy: 0.1940\n","Epoch 157/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0669 - accuracy: 0.9643 - val_loss: 0.3558 - val_accuracy: 0.2000\n","Epoch 158/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0664 - accuracy: 0.9643 - val_loss: 0.3551 - val_accuracy: 0.1820\n","Epoch 159/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0660 - accuracy: 0.9643 - val_loss: 0.3543 - val_accuracy: 0.1960\n","Epoch 160/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0656 - accuracy: 0.9714 - val_loss: 0.3558 - val_accuracy: 0.1860\n","Epoch 161/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0651 - accuracy: 0.9714 - val_loss: 0.3555 - val_accuracy: 0.2100\n","Epoch 162/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0647 - accuracy: 0.9714 - val_loss: 0.3533 - val_accuracy: 0.2400\n","Epoch 163/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0642 - accuracy: 0.9714 - val_loss: 0.3548 - val_accuracy: 0.2000\n","Epoch 164/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0638 - accuracy: 0.9714 - val_loss: 0.3548 - val_accuracy: 0.1860\n","Epoch 165/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0634 - accuracy: 0.9714 - val_loss: 0.3544 - val_accuracy: 0.2180\n","Epoch 166/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0629 - accuracy: 0.9714 - val_loss: 0.3555 - val_accuracy: 0.1840\n","Epoch 167/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0625 - accuracy: 0.9714 - val_loss: 0.3540 - val_accuracy: 0.2340\n","Epoch 168/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0621 - accuracy: 0.9786 - val_loss: 0.3539 - val_accuracy: 0.2120\n","Epoch 169/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0616 - accuracy: 0.9786 - val_loss: 0.3542 - val_accuracy: 0.2100\n","Epoch 170/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0612 - accuracy: 0.9786 - val_loss: 0.3534 - val_accuracy: 0.2200\n","Epoch 171/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0607 - accuracy: 0.9786 - val_loss: 0.3538 - val_accuracy: 0.2040\n","Epoch 172/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0603 - accuracy: 0.9786 - val_loss: 0.3530 - val_accuracy: 0.2300\n","Epoch 173/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0599 - accuracy: 0.9786 - val_loss: 0.3549 - val_accuracy: 0.2020\n","Epoch 174/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0594 - accuracy: 0.9786 - val_loss: 0.3517 - val_accuracy: 0.2400\n","Epoch 175/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0590 - accuracy: 0.9786 - val_loss: 0.3532 - val_accuracy: 0.2300\n","Epoch 176/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0586 - accuracy: 0.9786 - val_loss: 0.3536 - val_accuracy: 0.2000\n","Epoch 177/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0581 - accuracy: 0.9786 - val_loss: 0.3517 - val_accuracy: 0.2080\n","Epoch 178/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0577 - accuracy: 0.9786 - val_loss: 0.3542 - val_accuracy: 0.2260\n","Epoch 179/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0572 - accuracy: 0.9786 - val_loss: 0.3523 - val_accuracy: 0.2260\n","Epoch 180/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0568 - accuracy: 0.9786 - val_loss: 0.3526 - val_accuracy: 0.2020\n","Epoch 181/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0564 - accuracy: 0.9857 - val_loss: 0.3527 - val_accuracy: 0.1860\n","Epoch 182/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0559 - accuracy: 0.9857 - val_loss: 0.3538 - val_accuracy: 0.2120\n","Epoch 183/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0555 - accuracy: 0.9857 - val_loss: 0.3521 - val_accuracy: 0.2380\n","Epoch 184/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0550 - accuracy: 0.9857 - val_loss: 0.3528 - val_accuracy: 0.2300\n","Epoch 185/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0546 - accuracy: 0.9857 - val_loss: 0.3524 - val_accuracy: 0.2400\n","Epoch 186/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0542 - accuracy: 0.9857 - val_loss: 0.3539 - val_accuracy: 0.2440\n","Epoch 187/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0537 - accuracy: 0.9857 - val_loss: 0.3495 - val_accuracy: 0.2380\n","Epoch 188/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0533 - accuracy: 0.9857 - val_loss: 0.3519 - val_accuracy: 0.2200\n","Epoch 189/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0529 - accuracy: 0.9857 - val_loss: 0.3512 - val_accuracy: 0.2300\n","Epoch 190/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0524 - accuracy: 0.9857 - val_loss: 0.3525 - val_accuracy: 0.2460\n","Epoch 191/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0520 - accuracy: 0.9857 - val_loss: 0.3515 - val_accuracy: 0.2380\n","Epoch 192/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0516 - accuracy: 0.9857 - val_loss: 0.3521 - val_accuracy: 0.2320\n","Epoch 193/300\n","2708/2708 [==============================] - 0s 96us/sample - loss: 0.0511 - accuracy: 0.9857 - val_loss: 0.3537 - val_accuracy: 0.2300\n","Epoch 194/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0507 - accuracy: 0.9857 - val_loss: 0.3521 - val_accuracy: 0.2100\n","Epoch 195/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0503 - accuracy: 0.9857 - val_loss: 0.3508 - val_accuracy: 0.2520\n","Epoch 196/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0499 - accuracy: 0.9857 - val_loss: 0.3505 - val_accuracy: 0.2400\n","Epoch 197/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0494 - accuracy: 0.9857 - val_loss: 0.3489 - val_accuracy: 0.2640\n","Epoch 198/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0490 - accuracy: 0.9857 - val_loss: 0.3510 - val_accuracy: 0.2240\n","Epoch 199/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0486 - accuracy: 0.9857 - val_loss: 0.3508 - val_accuracy: 0.2420\n","Epoch 200/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0482 - accuracy: 0.9857 - val_loss: 0.3526 - val_accuracy: 0.2220\n","Epoch 201/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0477 - accuracy: 0.9857 - val_loss: 0.3531 - val_accuracy: 0.2440\n","Epoch 202/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0473 - accuracy: 0.9857 - val_loss: 0.3507 - val_accuracy: 0.2400\n","Epoch 203/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0469 - accuracy: 0.9857 - val_loss: 0.3511 - val_accuracy: 0.2320\n","Epoch 204/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0465 - accuracy: 0.9857 - val_loss: 0.3528 - val_accuracy: 0.2060\n","Epoch 205/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0461 - accuracy: 0.9857 - val_loss: 0.3510 - val_accuracy: 0.2380\n","Epoch 206/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0456 - accuracy: 0.9857 - val_loss: 0.3484 - val_accuracy: 0.2560\n","Epoch 207/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0452 - accuracy: 0.9857 - val_loss: 0.3519 - val_accuracy: 0.2300\n","Epoch 208/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0448 - accuracy: 0.9857 - val_loss: 0.3505 - val_accuracy: 0.2080\n","Epoch 209/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0444 - accuracy: 0.9857 - val_loss: 0.3492 - val_accuracy: 0.2320\n","Epoch 210/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0440 - accuracy: 0.9857 - val_loss: 0.3529 - val_accuracy: 0.2260\n","Epoch 211/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0436 - accuracy: 0.9857 - val_loss: 0.3489 - val_accuracy: 0.2280\n","Epoch 212/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0432 - accuracy: 0.9857 - val_loss: 0.3532 - val_accuracy: 0.2400\n","Epoch 213/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0427 - accuracy: 0.9857 - val_loss: 0.3516 - val_accuracy: 0.2000\n","Epoch 214/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0423 - accuracy: 0.9857 - val_loss: 0.3527 - val_accuracy: 0.2320\n","Epoch 215/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0419 - accuracy: 0.9857 - val_loss: 0.3487 - val_accuracy: 0.2680\n","Epoch 216/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0415 - accuracy: 0.9857 - val_loss: 0.3520 - val_accuracy: 0.2520\n","Epoch 217/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0411 - accuracy: 0.9857 - val_loss: 0.3485 - val_accuracy: 0.2440\n","Epoch 218/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0407 - accuracy: 0.9857 - val_loss: 0.3489 - val_accuracy: 0.2480\n","Epoch 219/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0403 - accuracy: 0.9857 - val_loss: 0.3505 - val_accuracy: 0.2200\n","Epoch 220/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0399 - accuracy: 0.9857 - val_loss: 0.3489 - val_accuracy: 0.2080\n","Epoch 221/300\n","2708/2708 [==============================] - 0s 97us/sample - loss: 0.0395 - accuracy: 0.9857 - val_loss: 0.3513 - val_accuracy: 0.2340\n","Epoch 222/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0392 - accuracy: 0.9857 - val_loss: 0.3503 - val_accuracy: 0.2320\n","Epoch 223/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0388 - accuracy: 0.9857 - val_loss: 0.3510 - val_accuracy: 0.2420\n","Epoch 224/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0384 - accuracy: 0.9857 - val_loss: 0.3521 - val_accuracy: 0.2380\n","Epoch 225/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0380 - accuracy: 0.9857 - val_loss: 0.3549 - val_accuracy: 0.2440\n","Epoch 226/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0376 - accuracy: 0.9857 - val_loss: 0.3504 - val_accuracy: 0.2120\n","Epoch 227/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0372 - accuracy: 0.9857 - val_loss: 0.3492 - val_accuracy: 0.2440\n","Epoch 228/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0369 - accuracy: 0.9857 - val_loss: 0.3497 - val_accuracy: 0.2580\n","Epoch 229/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0365 - accuracy: 0.9857 - val_loss: 0.3476 - val_accuracy: 0.2120\n","Epoch 230/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0361 - accuracy: 0.9857 - val_loss: 0.3502 - val_accuracy: 0.2420\n","Epoch 231/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0357 - accuracy: 0.9857 - val_loss: 0.3464 - val_accuracy: 0.2580\n","Epoch 232/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0354 - accuracy: 0.9929 - val_loss: 0.3539 - val_accuracy: 0.2360\n","Epoch 233/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0350 - accuracy: 0.9929 - val_loss: 0.3511 - val_accuracy: 0.2720\n","Epoch 234/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0346 - accuracy: 0.9929 - val_loss: 0.3518 - val_accuracy: 0.2260\n","Epoch 235/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0343 - accuracy: 0.9929 - val_loss: 0.3539 - val_accuracy: 0.2460\n","Epoch 236/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0339 - accuracy: 0.9929 - val_loss: 0.3504 - val_accuracy: 0.2240\n","Epoch 237/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0336 - accuracy: 0.9929 - val_loss: 0.3508 - val_accuracy: 0.2380\n","Epoch 238/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0332 - accuracy: 0.9929 - val_loss: 0.3479 - val_accuracy: 0.2520\n","Epoch 239/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0329 - accuracy: 0.9929 - val_loss: 0.3529 - val_accuracy: 0.2300\n","Epoch 240/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0325 - accuracy: 0.9929 - val_loss: 0.3484 - val_accuracy: 0.2320\n","Epoch 241/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0322 - accuracy: 0.9929 - val_loss: 0.3486 - val_accuracy: 0.2340\n","Epoch 242/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0318 - accuracy: 0.9929 - val_loss: 0.3488 - val_accuracy: 0.2620\n","Epoch 243/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0315 - accuracy: 0.9929 - val_loss: 0.3525 - val_accuracy: 0.2120\n","Epoch 244/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0311 - accuracy: 0.9929 - val_loss: 0.3508 - val_accuracy: 0.2440\n","Epoch 245/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0308 - accuracy: 0.9929 - val_loss: 0.3502 - val_accuracy: 0.2360\n","Epoch 246/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0305 - accuracy: 0.9929 - val_loss: 0.3559 - val_accuracy: 0.2080\n","Epoch 247/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0301 - accuracy: 0.9929 - val_loss: 0.3477 - val_accuracy: 0.2720\n","Epoch 248/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0298 - accuracy: 0.9929 - val_loss: 0.3506 - val_accuracy: 0.2220\n","Epoch 249/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0295 - accuracy: 0.9929 - val_loss: 0.3511 - val_accuracy: 0.2360\n","Epoch 250/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0291 - accuracy: 0.9929 - val_loss: 0.3514 - val_accuracy: 0.2300\n","Epoch 251/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0288 - accuracy: 0.9929 - val_loss: 0.3528 - val_accuracy: 0.2160\n","Epoch 252/300\n","2708/2708 [==============================] - 0s 91us/sample - loss: 0.0285 - accuracy: 0.9929 - val_loss: 0.3486 - val_accuracy: 0.2500\n","Epoch 253/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0282 - accuracy: 0.9929 - val_loss: 0.3499 - val_accuracy: 0.2280\n","Epoch 254/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0279 - accuracy: 0.9929 - val_loss: 0.3511 - val_accuracy: 0.2380\n","Epoch 255/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0276 - accuracy: 0.9929 - val_loss: 0.3502 - val_accuracy: 0.2220\n","Epoch 256/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0272 - accuracy: 0.9929 - val_loss: 0.3528 - val_accuracy: 0.2260\n","Epoch 257/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0269 - accuracy: 0.9929 - val_loss: 0.3496 - val_accuracy: 0.2420\n","Epoch 258/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0266 - accuracy: 0.9929 - val_loss: 0.3498 - val_accuracy: 0.2380\n","Epoch 259/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0263 - accuracy: 0.9929 - val_loss: 0.3541 - val_accuracy: 0.2600\n","Epoch 260/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0260 - accuracy: 0.9929 - val_loss: 0.3521 - val_accuracy: 0.2260\n","Epoch 261/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0257 - accuracy: 0.9929 - val_loss: 0.3520 - val_accuracy: 0.2140\n","Epoch 262/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0254 - accuracy: 0.9929 - val_loss: 0.3521 - val_accuracy: 0.2180\n","Epoch 263/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0251 - accuracy: 0.9929 - val_loss: 0.3502 - val_accuracy: 0.2480\n","Epoch 264/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0248 - accuracy: 0.9929 - val_loss: 0.3535 - val_accuracy: 0.2380\n","Epoch 265/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0245 - accuracy: 0.9929 - val_loss: 0.3576 - val_accuracy: 0.2100\n","Epoch 266/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0242 - accuracy: 0.9929 - val_loss: 0.3497 - val_accuracy: 0.2440\n","Epoch 267/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0240 - accuracy: 0.9929 - val_loss: 0.3526 - val_accuracy: 0.2320\n","Epoch 268/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0237 - accuracy: 0.9929 - val_loss: 0.3546 - val_accuracy: 0.1840\n","Epoch 269/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.3530 - val_accuracy: 0.2140\n","Epoch 270/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0231 - accuracy: 0.9929 - val_loss: 0.3502 - val_accuracy: 0.2240\n","Epoch 271/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.3457 - val_accuracy: 0.2480\n","Epoch 272/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0226 - accuracy: 0.9929 - val_loss: 0.3536 - val_accuracy: 0.2420\n","Epoch 273/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0223 - accuracy: 0.9929 - val_loss: 0.3552 - val_accuracy: 0.2300\n","Epoch 274/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.3544 - val_accuracy: 0.2020\n","Epoch 275/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0217 - accuracy: 0.9929 - val_loss: 0.3483 - val_accuracy: 0.2360\n","Epoch 276/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0215 - accuracy: 0.9929 - val_loss: 0.3496 - val_accuracy: 0.2360\n","Epoch 277/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0212 - accuracy: 0.9929 - val_loss: 0.3521 - val_accuracy: 0.2200\n","Epoch 278/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0209 - accuracy: 0.9929 - val_loss: 0.3561 - val_accuracy: 0.2020\n","Epoch 279/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.3500 - val_accuracy: 0.2460\n","Epoch 280/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.3526 - val_accuracy: 0.2260\n","Epoch 281/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0202 - accuracy: 0.9929 - val_loss: 0.3520 - val_accuracy: 0.2200\n","Epoch 282/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0199 - accuracy: 0.9929 - val_loss: 0.3500 - val_accuracy: 0.2460\n","Epoch 283/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0197 - accuracy: 0.9929 - val_loss: 0.3526 - val_accuracy: 0.2040\n","Epoch 284/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0194 - accuracy: 0.9929 - val_loss: 0.3502 - val_accuracy: 0.2240\n","Epoch 285/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0192 - accuracy: 0.9929 - val_loss: 0.3501 - val_accuracy: 0.2460\n","Epoch 286/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0189 - accuracy: 0.9929 - val_loss: 0.3566 - val_accuracy: 0.2300\n","Epoch 287/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0187 - accuracy: 0.9929 - val_loss: 0.3500 - val_accuracy: 0.2120\n","Epoch 288/300\n","2708/2708 [==============================] - 0s 92us/sample - loss: 0.0185 - accuracy: 0.9929 - val_loss: 0.3482 - val_accuracy: 0.2480\n","Epoch 289/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0182 - accuracy: 0.9929 - val_loss: 0.3520 - val_accuracy: 0.2220\n","Epoch 290/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0180 - accuracy: 0.9929 - val_loss: 0.3517 - val_accuracy: 0.2240\n","Epoch 291/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0177 - accuracy: 0.9929 - val_loss: 0.3501 - val_accuracy: 0.2260\n","Epoch 292/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0175 - accuracy: 0.9929 - val_loss: 0.3550 - val_accuracy: 0.2220\n","Epoch 293/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0173 - accuracy: 0.9929 - val_loss: 0.3483 - val_accuracy: 0.2440\n","Epoch 294/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0171 - accuracy: 0.9929 - val_loss: 0.3525 - val_accuracy: 0.2420\n","Epoch 295/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0168 - accuracy: 0.9929 - val_loss: 0.3502 - val_accuracy: 0.2480\n","Epoch 296/300\n","2708/2708 [==============================] - 0s 96us/sample - loss: 0.0166 - accuracy: 0.9929 - val_loss: 0.3537 - val_accuracy: 0.1960\n","Epoch 297/300\n","2708/2708 [==============================] - 0s 95us/sample - loss: 0.0164 - accuracy: 0.9929 - val_loss: 0.3508 - val_accuracy: 0.2220\n","Epoch 298/300\n","2708/2708 [==============================] - 0s 94us/sample - loss: 0.0162 - accuracy: 0.9929 - val_loss: 0.3515 - val_accuracy: 0.2140\n","Epoch 299/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0160 - accuracy: 0.9929 - val_loss: 0.3553 - val_accuracy: 0.2060\n","Epoch 300/300\n","2708/2708 [==============================] - 0s 93us/sample - loss: 0.0157 - accuracy: 0.9929 - val_loss: 0.3539 - val_accuracy: 0.2220\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f80e53eefd0>"]},"metadata":{"tags":[]},"execution_count":67}]},{"metadata":{"id":"iO-ncDaVZH03","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}