{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MoNet.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"7HPxbz9IZ1xO","colab_type":"code","colab":{}},"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kIH9phOegalY","colab_type":"code","colab":{}},"cell_type":"code","source":["from __future__ import absolute_import, division, print_function\n","\n","!pip install tensorflow-gpu==2.0.0-alpha0\n","import tensorflow_datasets as tfds\n","import tensorflow as tf\n","\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","from tensorflow.keras.metrics import CategoricalAccuracy\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Layer, Dense, Flatten, Conv2D, Activation\n","from tensorflow.keras import Model\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5PIfldx7gczn","colab_type":"code","colab":{}},"cell_type":"code","source":["import os,sys,inspect\n","import os\n","import joblib\n","import tensorflow as tf\n","import numpy as np\n","import h5py\n","import scipy.sparse.linalg as la\n","import scipy.sparse as sp\n","import scipy\n","import time\n","import pickle\n","\n","import matplotlib.pyplot as plt\n","from matplotlib.backends.backend_pdf import PdfPages\n","%matplotlib inline\n","\n","import scipy.io as sio\n","# import process_data\n","\n","from google.colab import files"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m0SNsOTAotwp","colab_type":"code","colab":{}},"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 1\n","%aimport graph\n","%aimport coarsening\n","%aimport utils"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EXFo5cxHpBqH","colab_type":"code","colab":{}},"cell_type":"code","source":["# Graphs.\n","number_edges = 8\n","metric ='euclidean'\n","normalized_laplacian = True\n","coarsening_levels = 4\n","len_img = 28"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GA_7oCF3iSuG","colab_type":"code","colab":{}},"cell_type":"code","source":["# Load dataset from local\n","\n","# uploaded = files.upload()\n","\n","# for fn in uploaded.keys():\n","#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","#       name=fn, length=len(uploaded[fn])))\n"," "],"execution_count":0,"outputs":[]},{"metadata":{"id":"mXMSAHpUplhM","colab_type":"code","colab":{}},"cell_type":"code","source":["# Useful functions\n","\n","def grid_graph(m):\n","  z = graph.grid(m)  # normalized nodes coordinates\n","  dist, idx = graph.distance_sklearn_metrics(z, k=number_edges, metric=metric) \n","  #dist contains the distance of the 8 nearest neighbors for each node indicated in z sorted in ascending order\n","  #idx contains the indexes of the 8 nearest for each node sorted in ascending order by distance\n","\n","  A = graph.adjacency(dist, idx)  # graph.adjacency() builds a sparse matrix out of the identified edges computing similarities as: A_{ij} = e^(-dist_{ij}^2/sigma^2)\n","\n","  return A, z\n","\n","  \n","def plot_matrix(m):\n","  plt.figure(figsize = (10, 10))\n","  plt.imshow(m.toarray())\n","  plt.show\n","\n","\n","# def convert_coo_to_sparse_tensor(L):\n","#   indices = np.column_stack((L.row, L.col))\n","#   L = tf.SparseTensor(indices, L.data.astype('float32'), L.shape)\n","#   L = tf.sparse.reorder(L)\n","#   return L\n","\n","      \n","# def get_neighbour_indices(A, node_index):\n","#   indices = A.indices[tf.equal(A.indices[:,0], node_index)][:,1]\n","#   return indices\n","\n","  \n","# def get_neighbour_features(X, neighbour_indices):\n","#   X = tf.constant(X)\n","#   features = tf.gather(X, neighbour_indices)\n","#   return features\n","  \n","\n","def mask():\n","  space = np.arange(-1, 2)\n","  X, Y  = np.meshgrid(space,space)\n","  mask = np.array((X.ravel(), Y.ravel())).T\n","  mask = np.array([mask[:mask.shape[0]//2], mask[mask.shape[0]//2 + 1 :]])\n","  mask = mask.reshape((-1, 2))\n","#   plt.scatter(mask[:,0], mask[:,1])\n","#   plt.show()\n","#   mask = np.repeat(mask, (784)).reshape((784, 8, 2)).T\n","  return tf.constant(mask.astype(np.float32))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K0lm_TPFmTb2","colab_type":"code","outputId":"5432bde0-5999-4b5b-ad36-ad8d62e70884","executionInfo":{"status":"ok","timestamp":1555404545845,"user_tz":-120,"elapsed":989,"user":{"displayName":"Alessia Ruggeri","photoUrl":"","userId":"01098494933204128714"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# Load MNIST dataset\n","\n","mnist = tf.keras.datasets.mnist\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train = x_train.astype(np.float32) / 255\n","x_test = x_test.astype(np.float32) / 255\n","y_train = y_train.astype(np.float32) \n","y_test = y_test.astype(np.float32)\n","\n","val_n = len(x_train)//100 * 15\n","(x_val, y_val) = x_train[0:val_n], y_train[0:val_n]\n","(x_train, y_train) = x_train[val_n:], y_train[val_n:]\n","x_val = x_val.astype(np.float32)\n","y_val = y_val.astype(np.float32)\n","\n","# x_train = x_train.reshape(-1, len_img*len_img)\n","# x_val = x_val.reshape(-1, len_img*len_img)\n","# x_test = x_test.reshape(-1, len_img*len_img)\n","x_train = x_train.reshape(-1, len_img*len_img, 1)\n","x_val = x_val.reshape(-1, len_img*len_img, 1)\n","x_test = x_test.reshape(-1, len_img*len_img, 1)\n","\n","print(x_train.shape)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["(51000, 784, 1)\n"],"name":"stdout"}]},{"metadata":{"id":"Fh2rD3Ouo4JW","colab_type":"code","colab":{}},"cell_type":"code","source":["# Load adjacency matrix\n","\n","# A, nodes_coordinates = grid_graph(len_img)\n","# A = convert_coo_to_sparse_tensor(A.tocoo())\n","\n","# A_idx = tf.transpose(A.indices)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7ljTlcvPpcSO","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create adjacency matrix\n","l = x_train.shape[-2]\n","\n","z = graph.grid(28)\n","dist, idx = graph.distance_sklearn_metrics(z, k=number_edges, metric=metric) \n","cols = idx.ravel()\n","# We want 8 neighbours for each node (number_edges)\n","rows = np.arange(0,idx.shape[0]).repeat(number_edges)\n","idx = np.mat([rows, cols]).T\n","# Each edge has unitary weight\n","values = tf.ones(idx.shape[0])\n","A = tf.SparseTensor(indices=idx, values=values, dense_shape=(l,l))\n","\n","print(A.shape)\n","print(A.indices)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nOQkbsytkHqo","colab_type":"code","colab":{}},"cell_type":"code","source":["# Compute MNIST mask\n","u = mask()\n","print(u.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9Zza-BK0mNOh","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create Gaussian weightning \n","\n","class Weighting(Layer):\n","\n","  def __init__(self, A, u, d, **kwargs):\n","    self.A = A\n","    self.u = u\n","    self.d = d\n","    super(Weighting, self).__init__(**kwargs)\n","\n","  def build(self, input_shape):\n","    self.mu = self.add_weight(name='mu',\n","                              shape=(1, self.d),\n","                              initializer='uniform',\n","                              trainable=True)\n","    self.sigma = self.add_weight(name='sigma',\n","                                 shape=(1, self.d),\n","                                 initializer='uniform',\n","                                 trainable=True)\n","    super(Weighting, self).build(input_shape)  \n","\n","  def call(self, X):\n","    diff =  (self.u - self.mu)**2\n","    factor = 1e-14 + self.sigma**2\n","    weights = -0.5 * (diff / factor)\n","#     weights = (8, 2)\n","    weights = tf.math.reduce_sum(weights, axis=-1)\n","#     weights = (8,1)\n","    weights = tf.math.softmax(weights, axis=0)\n","#     repeat it for 784 nodes\n","    weights = tf.ones([tf.shape(X)[0], weights.shape[0]]) * weights\n","#     weights = tf.reshape(weights, shape=[1,weights.shape[0]])\n","#     multiples = tf.constant(np.array([n_nodes, 1]))\n","#     weights = tf.tile(weights, multiples)\n","    weights = tf.SparseTensor(indices=self.A.indices,\n","                              values=tf.squeeze(tf.reshape(weights, (-1,1))), \n","                              dense_shape=(self.A.dense_shape))\n","    \n","    neighbours_idxs = self.A.indices[:,1] \n","    neighbours_features = tf.gather(X, self.A.indices[:,1], axis=-1)\n","    neighbours_features = tf.reshape(neighbours_features, (784, 8))\n","#     now that, for each node in the graph, I have the 8 neighbours' features, I can weight them with the gaussian weights already created\n","    weighted_neighbours_features = tf.sparse.sparse_dense_matmul(weights, neighbours_features)\n","#     obtained the 8 neighbours' weighted features for each node (784,8), I can sum up over the neighbours\n","    D = tf.reduce_sum(weighted_neighbours_features, axis=-1)\n","    \n","    return D\n","    \n","  def compute_output_shape(self, input_shape):\n","    return (input_shape[0], self.output_dim)\n","\n","  \n","# Create Gaussian (kernel) layer\n","\n","class MoNet(Layer):\n","\n","  def __init__(self, A, u, d, n_gaussian, n_classes, **kwargs):\n","    self.A = A\n","    self.u = u\n","    self.d = d\n","    self.n_gaussian = n_gaussian\n","    self.n_classes = n_classes\n","    self.weightings = []\n","    for k in range(self.n_gaussian):\n","      weighting = Weighting(self.A, self.u, self.d)\n","      self.weightings.append(weighting)\n","    super(MoNet, self).__init__(**kwargs)\n","\n","  def build(self, input_shape):\n","    self.W = self.add_weight(name='W', \n","                             shape=(input_shape[-2], self.n_classes),\n","                             initializer='uniform',\n","                             trainable=True)\n","\n","    super(MoNet, self).build(input_shape)  # Be sure to call this at the end\n","\n","  def call(self, X):\n","    X = tf.squeeze(X)\n","    \n","    weightings = []\n","    for k in range(self.n_gaussian):\n","      weighting = self.weightings[k](X)\n","      weightings.append(weighting)\n","    \n","    h = tf.add_n(weightings)\n","#     print(h.shape)\n","    h = tf.reshape(h, shape=[1, tf.shape(h)[0]])\n","#     print(h.shape)\n","    h = h @ self.W\n","    h = tf.squeeze(h)\n","\n","    return h\n","\n","  def compute_output_shape(self, input_shape):\n","    return (input_shape[0], self.output_dim)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sLHNVf93Nn6u","colab_type":"code","colab":{}},"cell_type":"code","source":["# class MoNet(Layer):\n","\n","#   def __init__(self, A, u, d, n_gaussian, n_classes, batch_size, **kwargs):\n","#     self.A = A\n","#     self.u = u\n","#     self.d = d\n","#     self.n_gaussian = n_gaussian\n","#     self.n_classes = n_classes\n","#     self.batch_size = batch_size\n","#     self.weightings = []\n","#     for k in range(self.n_gaussian):\n","#       weighting = Weighting(self.A, self.u, self.d)\n","#       self.weightings.append(weighting)\n","#     super(MoNet, self).__init__(**kwargs)\n","\n","#   def build(self, input_shape):\n","#     self.W = self.add_weight(name='W', \n","#                              shape=(input_shape[-2], self.n_classes),\n","#                              initializer='uniform',\n","#                              trainable=True)\n","\n","#     super(MoNet, self).build(input_shape)  # Be sure to call this at the end\n","\n","#   def gaussian(self, X):\n","#     X = tf.squeeze(X)\n","    \n","#     weightings = []\n","#     for k in range(self.n_gaussian):\n","#       weighting = self.weightings[k](X)\n","#       weightings.append(weighting)\n","    \n","#     h = tf.add_n(weightings)\n","#     h = tf.reshape(h, shape=[1, tf.shape(h)[0]])\n","    \n","#     return h\n","    \n","#   def call(self, X):\n","#     if self.batch_size > 1:\n","#       h = tf.concat([self.gaussian(x) for x in X], axis=0)\n","#     else:\n","#       h = self.gaussian(X)\n","    \n","#     h = h @ self.W\n","#     h = tf.squeeze(h)\n","    \n","#     return h\n","\n","#   def compute_output_shape(self, input_shape):\n","#     return (input_shape[0], self.output_dim)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yTY1XkVFmO6j","colab_type":"code","colab":{}},"cell_type":"code","source":["# Hyperparameters\n","\n","epochs=5\n","batch_size = 1\n","d = 2\n","n = 8\n","n_classes=10"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zye12JRhWRPc","colab_type":"code","colab":{}},"cell_type":"code","source":["# Build the model\n","\n","model = Sequential()\n","model.add(MoNet(A=A, u=u, d=d, n_gaussian=5, n_classes=n_classes))\n","# model.add(Activation('softmax'))\n","\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy')\n","\n","# model.compile(optimizer='adam',\n","#               loss='categorical_crossentropy',\n","#               metrics=['categorical_accuracy'])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Mo0ke2hPVST0","colab_type":"code","outputId":"2dfd86f0-460d-47b2-ce0c-8b186d59e828","executionInfo":{"status":"ok","timestamp":1555408307394,"user_tz":-120,"elapsed":1685664,"user":{"displayName":"Alessia Ruggeri","photoUrl":"","userId":"01098494933204128714"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"cell_type":"code","source":["# Train the model\n","# %%time\n","model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, batch_size=batch_size, shuffle=False)"],"execution_count":54,"outputs":[{"output_type":"stream","text":["Train on 51000 samples, validate on 9000 samples\n","Epoch 1/5\n","51000/51000 [==============================] - 343s 7ms/sample - loss: 35.9239 - val_loss: 35.7811\n","Epoch 2/5\n","51000/51000 [==============================] - 342s 7ms/sample - loss: 35.9171 - val_loss: 35.7811\n","Epoch 3/5\n","51000/51000 [==============================] - 333s 7ms/sample - loss: 35.9171 - val_loss: 35.7811\n","Epoch 4/5\n","51000/51000 [==============================] - 333s 7ms/sample - loss: 35.9171 - val_loss: 35.7811\n","Epoch 5/5\n","51000/51000 [==============================] - 331s 6ms/sample - loss: 35.9171 - val_loss: 35.7811\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f7416259d68>"]},"metadata":{"tags":[]},"execution_count":54}]},{"metadata":{"id":"PjM9d2Ktxpgx","colab_type":"code","colab":{}},"cell_type":"code","source":["# k = Weighting(A, u, d)\n","# a = k(x_train[0,:])\n","# print(a)\n","k = MoNet(A, u, d, 25, n_classes)\n","k(x_train[0,:,:])\n","# print(x_train[0:5,:,:].shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6ca3RBZrwTjO","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}